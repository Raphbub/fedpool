{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupérer des images depuis swisstopo\n",
    "\n",
    "Le but de ce notebook est de tester la possibilité d'utiliser l'API STAC (SpatioTemporal Asset Catalog) afin de lister et télécharger des images d'intérêt depuis swisstopo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération du nom du jeu de données SWISSIMAGES via l'API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut récupérer le nom du jeu de données [SWISSMAGES](https://www.swisstopo.admin.ch/fr/orthophotos-swissimage-10-cm). Les [infos générales](https://www.geo.admin.ch/fr/interface-rest-api-stac/) de l'API indiquent que l'adresse principale est `https://data.geo.admin.ch/api/stac/v0.9/` et la documentation détaillée est disponible [ici](https://data.geo.admin.ch/api/stac/static/spec/v0.9/api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_api_url = (\"https://data.geo.admin.ch/api/stac/v0.9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère les ids de toutes les collections disponibles ([doc](https://data.geo.admin.ch/api/stac/static/spec/v0.9/api.html#tag/Data/operation/getCollections)). Attention, les collections sont limités à 100 dans l'array `collections` retourné. Il faut utiliser le lien avec la `rel : \"next\"` contenu dans l'array `links` de l'objet contenant `{collections : [...], links : [...]}` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch.agroscope.feuchtflaechenpotential-kulturlandschaft\n",
      "ch.are.agglomerationsverkehr\n",
      "ch.are.alpenkonvention\n"
     ]
    }
   ],
   "source": [
    "# Stockage des ids\n",
    "collection_ids = []\n",
    "\n",
    "# GET sur les collections\n",
    "response = requests.get(f\"{stac_api_url}/collections\")\n",
    "\n",
    "# Vérification du succès\n",
    "if response.status_code == 200:\n",
    "    # Parse le json\n",
    "    collections_data = response.json()\n",
    "\n",
    "    # Extraire les ids des collections\n",
    "    collection_ids.extend(collection[\"id\"] for collection in collections_data.get(\"collections\"))\n",
    "\n",
    "    # Enchaîner avec les prochaines pages/liens\n",
    "    while True:\n",
    "        # Récupère le lien avec next ou retourne None si absent (dernier lien)\n",
    "        next_link = next((link for link in collections_data.get(\"links\") if link.get(\"rel\") == \"next\"), None)\n",
    "        if next_link:\n",
    "            # Récupérer l'url\n",
    "            next_url = next_link[\"href\"]\n",
    "\n",
    "            # Répéter les opérations précédentes\n",
    "            response = requests.get(next_url)\n",
    "            \n",
    "            # Vérification du succès\n",
    "            if response.status_code == 200:\n",
    "                # Parse le json\n",
    "                collections_data = response.json()\n",
    "\n",
    "                # Extraire les ids des collections\n",
    "                collection_ids.extend(collection[\"id\"] for collection in collections_data.get(\"collections\"))\n",
    "            else:\n",
    "                print(\"Échec. Erreur\", response.status_code)\n",
    "                break\n",
    "        else:\n",
    "            break  # Plus de lien \"next\"\n",
    "else:\n",
    "    print(\"Échec. Erreur\", response.status_code)\n",
    "\n",
    "print('\\n'.join(collection_ids[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On identifie les fournisseurs de données, qui viennent juste après le `ch.`. Ce sont généralement les abréviations allemandes des offices fédéraux (are (ODT), astra (OFROU), etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agroscope', 'are', 'armasuisse', 'astra', 'babs', 'bafu', 'bag', 'bak', 'bakom', 'baspo', 'bav', 'bazl', 'bfe', 'bfs', 'blw', 'ensi', 'meteoschweiz', 'pronatura', 'sem', 'swisstopo', 'swisstopo-vd', 'vbs']\n"
     ]
    }
   ],
   "source": [
    "fournisseurs = set(id.split(\".\")[1] for id in collection_ids)\n",
    "print(sorted(fournisseurs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le founisseur qui nous intéresse est `swisstopo`, on regarde donc les jeux de données mis à disposition qui contiennent le mot `image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch.swisstopo.swissimage-dop10\n"
     ]
    }
   ],
   "source": [
    "for collection_id in collection_ids:\n",
    "    if \"swisstopo\" in collection_id and \"image\" in collection_id:\n",
    "        print(collection_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données des images est donc `ch.swisstopo.swissimage-dop10`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de données SWISSIMAGE - Infos et téléchargement(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_swimage = \"ch.swisstopo.swissimage-dop10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The orthophoto mosaic SWISSIMAGE 10 cm is a composition of new digital color aerial photographs over the whole of Switzerland with a ground resolution of 10 cm in the plain areas and main alpine valleys and 25 cm over the Alps. It is updated in a cycle of 3 years since 2018.'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET sur le jeu de données\n",
    "response = requests.get(f\"{stac_api_url}/collections/{id_swimage}\")\n",
    "infos_jdd = response.json()\n",
    "# La description en anglais du jdd\n",
    "infos_jdd.get(\"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'proj:epsg': [2056], 'eo:gsd': [0.1, 2.0]}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Système de projection et résolution des images\n",
    "infos_jdd.get(\"summaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de restreindre la recherche à l'aide de la bbox de la zone.\n",
    "Par exemple, on pourrait donner la suivante (format xmin, ymin, xmax, ymax) `bbox=7.34791,46.23141,7.36087,46.24042` afin de trouver toutes les images correspondant à cette zone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymin, xmin, ymax, xmax = 46.23141, 7.34791, 46.24042, 7.36087\n",
    "bbox = [xmin, ymin, xmax, ymax]\n",
    "response = requests.get(f\"{stac_api_url}/collections/{id_swimage}/items?bbox={\", \".join(str(coord) for coord in bbox)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = response.json().get(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46.23141, 7.34791, 46.24042, 7.36087 || 2593-1120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2017_2593-1119/swissimage-dop10_2017_2593-1119_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2017_2593-1120/swissimage-dop10_2017_2593-1120_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2017_2593-1121/swissimage-dop10_2017_2593-1121_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2017_2594-1120/swissimage-dop10_2017_2594-1120_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2017_2594-1121/swissimage-dop10_2017_2594-1121_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2593-1119/swissimage-dop10_2020_2593-1119_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2593-1120/swissimage-dop10_2020_2593-1120_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2593-1121/swissimage-dop10_2020_2593-1121_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2594-1120/swissimage-dop10_2020_2594-1120_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2594-1121/swissimage-dop10_2020_2594-1121_0.1_2056.tif']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets_links = []\n",
    "\n",
    "for feature in features:\n",
    "    for name, properties in feature.get(\"assets\").items():\n",
    "        if properties.get('eo:gsd') == 0.1:\n",
    "            assets_links.append(properties.get('href'))\n",
    "assets_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2593-1119/swissimage-dop10_2020_2593-1119_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2593-1120/swissimage-dop10_2020_2593-1120_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2593-1121/swissimage-dop10_2020_2593-1121_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2594-1120/swissimage-dop10_2020_2594-1120_0.1_2056.tif',\n",
       " 'https://data.geo.admin.ch/ch.swisstopo.swissimage-dop10/swissimage-dop10_2020_2594-1121/swissimage-dop10_2020_2594-1121_0.1_2056.tif']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_years = {}\n",
    "\n",
    "for url in assets_links:\n",
    "    # Extraire l'id de l'image \"XXXX-XXXX\"\n",
    "    image_id = url.split('/')[-2].split('_')[2]\n",
    "\n",
    "    # Extraire l'année de l'image \n",
    "    year = int(url.split('_')[1])\n",
    "\n",
    "    # Ajouter l'année max correspondant à l'image\n",
    "    if image_id in image_years:\n",
    "        image_years[image_id] = max(image_years[image_id], year)\n",
    "    else:\n",
    "        image_years[image_id] = year\n",
    "\n",
    "# Garder uniquement les urls avec l'image la plus récente\n",
    "most_recent_assets_links = [\n",
    "    url for url in assets_links if int(url.split('/')[-2].split('_')[1]) == image_years[url.split('/')[-2].split('_')[2]]\n",
    "]\n",
    "most_recent_assets_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Télécharger les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in most_recent_assets_links:\n",
    "    filename = url.split('/')[-1]\n",
    "    filename = filename.split(\"_\")[2] + \".tif\"\n",
    "    filepath = os.path.join(\"../data\", \"download_test\", filename)\n",
    "    response = requests.get(url)\n",
    "    with open(filepath, 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement à l'aide des bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regrouper les étapes précédentes dans une fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(xmin, ymin, xmax, ymax, output_dir):\n",
    "    # URL STAC\n",
    "    stac_api_url = (\"https://data.geo.admin.ch/api/stac/v0.9\")\n",
    "    # ID jdd\n",
    "    id_swimage = \"ch.swisstopo.swissimage-dop10\"\n",
    "    \n",
    "    # Regrouper en bbox array\n",
    "    bbox = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "    # Faire la requete\n",
    "    response = requests.get(f\"{stac_api_url}/collections/{id_swimage}/items?bbox={','.join(str(coord) for coord in bbox)}\")\n",
    "    features = response.json().get('features', [])\n",
    "\n",
    "    # Extraire les urls\n",
    "    assets_links = []\n",
    "    for feature in features:\n",
    "        for name, properties in feature.get(\"assets\", {}).items():\n",
    "            if properties.get('eo:gsd') == 0.1:\n",
    "                assets_links.append(properties.get('href'))\n",
    "\n",
    "    # Trouver les images les plus récentes\n",
    "    image_years = {}\n",
    "    for url in assets_links:\n",
    "        image_id = url.split('/')[-2].split('_')[2]\n",
    "        year = int(url.split('_')[1])\n",
    "        if image_id in image_years:\n",
    "            image_years[image_id] = max(image_years[image_id], year)\n",
    "        else:\n",
    "            image_years[image_id] = year\n",
    "\n",
    "    # Liste des urls des images les plus récentes\n",
    "    most_recent_assets_links = [\n",
    "        url for url in assets_links if int(url.split('/')[-2].split('_')[1]) == image_years[url.split('/')[-2].split('_')[2]]\n",
    "    ]\n",
    "\n",
    "    nb_images = len(most_recent_assets_links)\n",
    "\n",
    "    # S'assurer que la sortie existe\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Télécharger les images\n",
    "    for url in most_recent_assets_links:\n",
    "        filename = url.split('/')[-1]\n",
    "        filename = filename.split(\"_\")[2] + \".tif\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            nb_images -= 1\n",
    "            continue\n",
    "        response = requests.get(url)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    \n",
    "    return nb_images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/bounding_boxes.json\", 'r', encoding=\"utf-8\") as file:\n",
    "    bounding_boxes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 0 images.\n",
      "Downloaded 1 images.\n",
      "Downloaded 1 images.\n"
     ]
    }
   ],
   "source": [
    "for bbox in bounding_boxes:\n",
    "    nb_imgs = download_images(bbox[\"xmin\"], bbox[\"ymin\"], bbox[\"xmax\"], bbox[\"ymax\"], \"../data/download_by_bbox\")\n",
    "    print(f\"Downloaded {nb_imgs} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
